{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e262b60-a61c-4fb6-adfb-c00d1ebda073",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>eSBAE - Notebook Series - Part 3, version 0.4, March 2023. Andreas Vollrath, UN-Food and Agricultural Organization, Rome</i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64fe01-50b8-4280-9629-1445ad541e45",
   "metadata": {},
   "source": [
    "![title](images/header.png)\n",
    "\n",
    "# III - eSBAE Time-Series Extraction\n",
    "### Extract various time-series data for large sets of points from Google Earth Engine\n",
    "-------\n",
    "\n",
    "This notebook takes you through the process of extracting time-series information for a set of points using [Google Earth Engine](https://earthengine.google.com/). The script is optimized to deal with thousands of points and will use parallelization to efficiently extract the information from the platform.\n",
    "\n",
    "**You will need**:\n",
    "- a valid Earth Engine account ([sign up here](https://code.earthengine.google.com/register))\n",
    "- an uploaded table of points (Feature Collection) \n",
    "- the table needs a unique point identifier (Point ID)\n",
    "\n",
    "**You should be aware, that:** \n",
    "\n",
    "- As a SEPAL user: this notebook does **not need huge resources**, as processing is done on the platform. An **m2 instance** is best suited.  \n",
    "- The extraction can take up to days (>100000 points). If you are on SEPAL, make use of the **\"keep instance running\"** option within the user report dashboard.\n",
    "  - You do this by clicking on the cost per hour shown at the bottom right of your screen. Select the edit button on the right side under \"sessions\", then move the slider to the right until several days are selected and close the window. However, **do not forget** to shut down your machine once processing has finished or you will continue to be charged. \n",
    "- Interruption of connectivity to the SEPAL server may block the output of the Jupyter notebook. **This does not mean the processing stopped.** A logfile is created within your \"tmp\" folder where you can check if there is an issue.\n",
    "    - Go to your \"tmp\" folder by making sure the File Browser icon is selected from the four tabs on the left of your Jupyter Notebooks screen, then click on the folder icon on the far left of the displayed path to your working folder. This will take you one directory up from your working folder where the \"tmp\" folder is located. Inside the \"tmp\" folder you can see the \"Last Modified\" times. Check to see that the last modified time was within the last few minutes when you ran the code cell (proving the processing is still ongoing). If the last modified time seems far too long ago, try checking your instance is still active (there should be a non-zero cost per hour on the bottom of your screen) and then **restarting the kernel and running all the cells again**.  \n",
    "- If you restart the kernel and execute all cells, extraction will **start where it stopped**. This is also valid if your instance has been shut down before processing was completely finished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f9d9a-8a0d-4d85-b134-f0bda3727152",
   "metadata": {},
   "source": [
    "### 1 - Import libraries\n",
    "\n",
    "This cell will provide us with the functionality we need for running the subsequent cells of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75e78de-8687-4632-8586-9ca964b31045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/bfast/__init__.py:10: UserWarning: cupy is not available in this environment, GPU fonctionnalities won't be available\n",
      "  warn(\"cupy is not available in this environment, GPU fonctionnalities won't be available\")\n"
     ]
    }
   ],
   "source": [
    "# initialize EE    \n",
    "import ee\n",
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "    \n",
    "from sampling_handler import TimeSeriesExtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c04e79-5bfe-48d9-8412-c17707d7c5e9",
   "metadata": {},
   "source": [
    "### 2 - Basic Input Variables\n",
    "\n",
    "Here a class instance is initialized. The class instance needs some parameters to be set and is written into the *esbae* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c8d21f-1d84-44b2-9b44-3458bc7ff444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using existing project directory at /home/sepal-user/module_results/esbae/my_first_esbae_project\n",
      "INFO: Using existent config file from project directory /home/sepal-user/module_results/esbae/my_first_esbae_project\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It seems a different AOI is already defined within your configuration. Do you want to overwrite it (yes/no) yes\n"
     ]
    }
   ],
   "source": [
    "esbae = TimeSeriesExtraction(\n",
    "     # your project name that you use for all of the notebooks\n",
    "    project_name  = 'my_first_esbae_project',\n",
    "    \n",
    "    # your start and end date \n",
    "    # NOTE: this start date should go further back in the past than the \n",
    "    # envisaged monitoing period for calibration purposes\n",
    "    ts_start      = '2015-01-01',      # YYYY-MM-DD format\n",
    "    ts_end        = '2023-01-01',      # YYYY-MM-DD format\n",
    "    \n",
    "    # satellite platform (for now, only Landsat is supported)\n",
    "    satellite     = 'Landsat',\n",
    "    \n",
    "    # at what resolution in metres you want to extract (should conform with forest definition MMU)\n",
    "    scale         = 70, # pixel size in metres\n",
    "    \n",
    "    # wether the time series will be extracted on a bounding box with diameter scale with original scale (e.g. 30m for Landsat) of the underlying data (True), \n",
    "    # or if the underlying data is rescaled to the scale (False)\n",
    "    # setting it to True might be more accurate, but tends to be slower\n",
    "    bounds_reduce = False,\n",
    "    \n",
    "    # bands\n",
    "    bands         =  [\n",
    "        'green', 'red', 'nir', 'swir1', 'swir2',   # reflectance bands\n",
    "        'ndfi', #'ndmi', 'ndvi',                    # indices\n",
    "        'brightness', 'greenness', 'wetness'       # Tasseled Cap \n",
    "    ], \n",
    "    # Uncomment the text below in the case where you haven't run notebook 1 and 2, and want to directly start from here with an aoi defined by the geometry around an existing set of points.\n",
    "    # Change the string text to the asset path of your points feature collection\n",
    "    # aoi = ee.FeatureCollection(ee.FeatureCollection('users/username/my_points').geometry().convexHull(100))\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4dc5b2-3d18-429e-ae4a-5b16f677448a",
   "metadata": {},
   "source": [
    "### 3 - Landsat parameters\n",
    "\n",
    "Here you can select, which satellites you want to include from the Landsat mission.\n",
    "In addition you can select the BRDF correction and a filter for maximum cloud cover. Note that the bands parameter is already set in the initialization and will be taken from the class attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d1fb79-897c-4a86-9b02-16e2c7d85758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# landsat related parameters\n",
    "lsat_params = {\n",
    "    'l9': True,\n",
    "    'l8': True,\n",
    "    'l7': True,\n",
    "    'l5': True,\n",
    "    'l4': True,\n",
    "    'brdf': True,\n",
    "    'bands': esbae.bands,\n",
    "    'max_cc': 75    # percent\n",
    "} \n",
    "\n",
    "# apply the basic configuration set in the cell above\n",
    "esbae.lsat_params = lsat_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83cb8d-3f49-4bdf-ae77-25b1b13a6de3",
   "metadata": {},
   "source": [
    "### 4 - Processing parameters\n",
    "\n",
    "Here you can refine the parallelization options. For efficient extraction, the time-series extraction is done on chunks of data, defined by squared grids of given sizes. The routine will check how many points are in each chunk. If this is below the max_points_per_chunk, it will go on and process those points. Otherwise it will try to process those points at a lower grid size level. Some optimized settings are given below, comment and uncomment as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c99611d-a405-49c1-941f-4700cda2e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "esbae.workers = 10                   # this defines how many parallel requests will be send to EarthEngine at a time\n",
    "esbae.max_points_per_chunk = 100     # this defines the maximum amount of points as send per request to Earth Engine at a time\n",
    "\n",
    "# this defines the chunk sizes (in degree) to create the requests\n",
    "#esbae.grid_size_levels = [0.1, 0.075, 0.05]   # optimized for 1km systematic grid\n",
    "esbae.grid_size_levels = [0.2, 0.15, 0.1]    # optimized for 2km systematic grid\n",
    "#esbae.grid_size_levels = [0.4, 0.3, 0.2]     # optimized for 4km systematic grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae865d-43bf-495b-b6ce-e8be7fd12884",
   "metadata": {},
   "source": [
    "### 5 - Set a custom grid \n",
    "\n",
    "This step is only necessary if you skipped notebook 2. You then need to define an Earth Engine feature collection as well as the unique point identifier. Uncomment the lines of code by removing the # from the start of the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786e8355-4b7e-4f47-8a30-62ad5d8321c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#esbae.sample_asset = 'users/username/my_already_existing_points' \n",
    "#If you uncomment this, switch the asset path to your defined set of points, the same path you used when definint the aoi.\n",
    "\n",
    "#esbae.pid = 'my_unique_point_id'\n",
    "#If you uncomment this, change the text in the string to the name of the unique point ID from your points asset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed4350-c397-43eb-ab7e-fe795a24c831",
   "metadata": {},
   "source": [
    "### 4 - Check for already processed data (optional)\n",
    "\n",
    "This is useful for large points sizes and when the connection to Sepal gets interrupted. Usually processing will continue, but it is not straightforward to track progress. \n",
    "You can instead restart the kernel, execute all cells and see if processing has been finished with the following line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad269ed4-9e28-4d4b-a629-d05513d41376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Verifying the number of points for which the time-series have already been extracted...\n",
      "INFO: No time-series data has been extracted yet.\n"
     ]
    }
   ],
   "source": [
    "esbae.check_if_completed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c28df-5381-413c-924d-23830b97b87e",
   "metadata": {},
   "source": [
    "### 5 - Run the time-series data extraction *(only execute this)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ccf187-bba1-4e1a-a493-d646f51b9fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Verifying parameter settings...\n",
      "INFO: The number of points exceeds 25000. Processing will be split into 13 subsets.\n",
      "INFO: ------------------------------------------------\n",
      "INFO: Processing subset 1/13\n",
      "INFO: ------------------------------------------------\n",
      "INFO: No time-series data has been extracted yet.\n",
      "INFO: Create AOI from points and upload as temporary EE asset inside tmp_esbae_240326_141243.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'assets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mesbae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_time_series_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/sampling_handler/time_series/ts_extract.py:98\u001b[0m, in \u001b[0;36mTimeSeriesExtraction.get_time_series_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m config\u001b[38;5;241m.\u001b[39mupdate_config_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_file, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_dict)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# run extract routine\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureCollection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_asset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/sampling_handler/time_series/ts_extract.py:724\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(input_grid, config_dict)\u001b[0m\n\u001b[1;32m    722\u001b[0m _check_config_changed(config_dict)\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_grid, ee\u001b[38;5;241m.\u001b[39mFeatureCollection):\n\u001b[0;32m--> 724\u001b[0m     \u001b[43mcascaded_extraction_ee\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/sampling_handler/time_series/ts_extract.py:638\u001b[0m, in \u001b[0;36mcascaded_extraction_ee\u001b[0;34m(input_grid, config_dict)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_size \u001b[38;5;129;01min\u001b[39;00m chunk_sizes:\n\u001b[0;32m--> 638\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43m_parallel_extract_ee\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m25000\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChecking for points not processed at the current \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregation level.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    645\u001b[0m     )\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# if already processed files are in the tmp_folder\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/sampling_handler/time_series/ts_extract.py:487\u001b[0m, in \u001b[0;36m_parallel_extract_ee\u001b[0;34m(points_fc, chunk_size, config_dict, subset)\u001b[0m\n\u001b[1;32m    482\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreate AOI from points and upload as temporary EE asset \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minside tmp_esbae_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgmt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    485\u001b[0m )\n\u001b[1;32m    486\u001b[0m aoi_fc \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mFeatureCollection(points_fc\u001b[38;5;241m.\u001b[39mgeometry()\u001b[38;5;241m.\u001b[39mconvexHull(\u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m--> 487\u001b[0m _, aoi_fc \u001b[38;5;241m=\u001b[39m \u001b[43meeh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ee_export_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mee_fc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maoi_fc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp_esbae_aoi_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgmt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43masset_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp_esbae_aoi_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgmt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp_esbae_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgmt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m aoi_fc \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mFeatureCollection(aoi_fc)\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLandsat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/sampling_handler/misc/ee_helpers.py:117\u001b[0m, in \u001b[0;36m_ee_export_table\u001b[0;34m(ee_fc, description, asset_id, sub_folder, wait_until_end)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ee_export_table\u001b[39m(ee_fc, description, asset_id, sub_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, wait_until_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# get users asset root\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m#asset_root = ee.data.getAssetRoots()[0][\"id\"]\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     asset_root \u001b[38;5;241m=\u001b[39m \u001b[43mget_legacy_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# if there is any subfolder,create it\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sub_folder:\n",
      "File \u001b[0;32m/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/sampling_handler/misc/ee_helpers.py:110\u001b[0m, in \u001b[0;36mget_legacy_root\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     request \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_url)\n\u001b[1;32m    108\u001b[0m     response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(request\u001b[38;5;241m.\u001b[39murl, headers\u001b[38;5;241m=\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43massets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'assets'"
     ]
    }
   ],
   "source": [
    "esbae.get_time_series_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbe0c2-114c-4832-b4e0-d845f572d906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": " (venv) Sample Based Area Estimation",
   "language": "python",
   "name": "venv-esbae_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
